---
title: "An Analysis of Spotify's Top 200 Worldwide Daily Song Rankings in 2017"
author: "Nathaniel Lao"
date: "5/18/2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# Introduction

_Spotify_ has become one of the most popular applications that offer music streaming on popular mobile and desktop devices. Due to its popularity, the streaming trends of _Spotify_ users can provide a sample of a song's popularity across the world. As a professional musician, I am curious of the life and death of top songs in the industry and I wish to gain some insight on whether or not it is beneficial to releases songs in batches (i.e. albums) or at one of a time (i.e. singles).

In this analysis, we will explore the common <!--- BLAH BLAH --->

<!--- MORE TOPICS --->
We can extract data from _Billboard Top 100 Songs of All Time_: http://billboardtop100of.com/ for analysis.

# Setting Up RStudio

For this project, we will need to install and mount a number libraries for use in analysis.

The libraries that are needed to be installed as dependencies for the `spotifyr` class are `stringdist` and `devtools`. We can then install the _devloper_ version of `spotifyr` from _GitHub_. These installation should only be called once per system.

```{r install_pck,eval=FALSE}
# The following is needed for the spotifyr package
install.packages('stringdist')
install.packages('devtools')
devtools::install_github('charlie86/spotifyr')
```

We can now mount the needed libraries.

```{r setup_pck,message=FALSE,error=FALSE}
library(dplyr)
library(tidyr)
library(lubridate)
library(stringr) # For string manpulation
library(spotifyr) # Allows for extracting metadata for songs
library(ggplot2)
```

# Data Wrangling

## Scraping Data from Spotify's Top 200

_Spotify_ keeps records of the daily _Top 200 Charts_ for various countries in a dedicated site: https://spotifycharts.com/. We can scrape data systematically by downloading the CSV file using the url: https://spotifycharts.com/regional/global/daily/YEAR-MO-DY/download. For this analysis, we will scrape data from the 'global' dataset in daily values. The scope of this analysis will consider the entire 2017 year: January 1st, 2017 until January 1st, 2018.

In order to pull data from the url, we will define the `start_date` and `end_date` variables as well as the `url_prefix` and the `url_suffix`. These strings will be concatenated to the front and end of the start date so as to have a proper final url for scraping. We can define a function, `get_top200` that accepts a date, appends the necessary strings together to form a URL and finally pull the `data.frame` object via the `read.csv` function. In addition to pull the data, we will mutate the data frame so as to have a `Date` attribute so that it will be easy to distinguish between entities (songs) of different dates.

```{r get_top200}
# Get start and end date
start_date <- as.Date("2017/1/1")
end_date <- as.Date("2018/1/1")

# Define URL prefix and suffix
url_prefix <- 'https://spotifycharts.com/regional/global/daily/'
url_suffix <- '/download'

# List of Column Names that should exist in the dataframe
col_names = c("Position","Track.Name","Artist","Streams","URL")

# Define a function that pulls data from a certain date
get_top200 <- function(date) {
  url <- str_c(url_prefix,
               format.Date(date),
               url_suffix)
  # Pull data from web
  top200_df <- read.csv(url)
  
  # There are sometimes file that do not exist, this handles the exception
  ifelse(all(colnames(top200_df) %in% col_names),
         top200_df <- top200_df %>% mutate(Date = date), # Create a date attribute
         top200_df <- data.frame()) # Return an empty data frame if invalid
  
  top200_df
}
```

We can now use the code to pull all of the data frames of the `Top 200 Global Songs` and combine them via the `rbind` function. (The `rbind` function basically combines two data frames, so long as they hae the same columns. Note that this is different from `join`, as `join` serves to resolve entities between two datasets.) Since importing the data from the web takes a relatively long time, it would be prudent to save the newly created data frame into a `csv` file.

```{r import_top200_setup}
# Set data directory
data_dir <- "data/"
get_path <- function(filename) {
  str_c(data_dir,filename)
}
```

We can now scrape the data directly from the Spotify website: _Note: this process takes a long time depending on your internet connection. We will export the data into a csv later so that this process will only need to be executed once. It is recommended to set _`eval=FALSE` _after saving the csv._

```{r import_top200,eval=FALSE}
date <- start_date # set data counter
top200_df <- data.frame() # initialize empty df

# Iterate every date from start to end
# And get top 200 songs
while (date <= end_date) {
  print(str_c("Processing ", date))
  top200_df <- top200_df %>%
    # Concat the current data frame with new data
    rbind(get_top200(date))
  date <- date + 1
}
```

For purposes of consistency, we will rename the columns of the data frame for future use. We will save the dataframe in to `csv` locally for future use.

```{r cleanup_export, eval=FALSE}
top200_df <- top200_df %>%
  rename(position = Position,
         track_name = Track.Name,
         artist_name = Artist,
         streams = Streams,
         url = URL,
         date = Date)

# Set filename
top200_filename <- "top200songs.csv"
# Save the file to csv
top200_df %>% 
  write.csv(get_path(top200_filename))
```

After saving the `csv` file, dataframe can be recalled by the following code:

```{r import_csv}
top200_df <- top200_filename %>%
  get_path %>%
  read.csv() %>%
  select(-X)
```

After scraping the website, we get this dataframe:

```{r}
top200_df %>%
  head(10)
```

## Retrieving Song Metadata using `spotifyr`

_Spotify_ is a developer friendly platform, an API is available for use in various languages: https://developer.spotify.com/. In the _R_ development language, there exists a wrapper library for the _Spotify_ API, `spotifyr` that can be used to extract data. Special thanks to _charlie86_ for this code: https://github.com/charlie86/spotifyr.

```{r client_login,eval=TRUE,include=FALSE}
client_id = 'f6eb05cabe1b40918336d70c9b9d157e'
client_secret = '5615c7eb790a471fba93915d37e8a367'
```

In order to use `spotifyr`, it is necessary to generate a `client_id` and a `client_secret` code from the developer site. Since these codes are not meant to be public, I have previously set the codes to their respective variables. The following code will set these values to System Environment variables `SPOTIFY_CLIENT_ID` and `SPOTIFY_CLIENT_SECRET` which will be used by the `get_spotify_access_token()` method present in every `spotifyr` requests.

```{r setup_spotifyr,eval=TRUE}
Sys.setenv(SPOTIFY_CLIENT_ID = client_id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = client_secret)
```


### SAMPLE CODE FOR TESTING

### TEST 1

```{r, eval = FALSE}
albums <- get_artist_albums('the beatles')
```
```{r, eval= FALSE}
tracks <- albums %>% left_join(get_album_tracks(.),.)
```

```{r, eval = FALSE}
tracks %>% 
  filter(album_name == "Sgt. Peppers Lonely Hearts Club Band (Deluxe Edition)") %>%
  full_join(.,get_track_audio_features(.))
```

### TEST 2

```{r,eval=FALSE}
beatles_df <- get_artist_audio_features('The Beatles') 
led_zeppelin_df <- get_artist_audio_features('Led Zeppelin')
rolling_stones_df <- get_artist_audio_features('The Rolling Stones')
```

```{r,eval=FALSE}
band_df <- rolling_stones_df
```

```{r,eval=FALSE}
## GET THE ACOUSTICNESS OF SONGS
band_df %>%
  select(track_name, acousticness) %>%
  arrange(desc(acousticness)) %>%
  mutate(acousticness = round(acousticness * 100)) %>%
  unique()
```

```{r, eval=FALSE}
band_df %>%
  ggplot(mapping=aes(x=tempo)) +
  geom_density()
```

### TEST 3

Sample 10 songs for top 200

```{r, eval=FALSE}
test_df <- top200_df %>%
  sample_n(10)
```

Create a vector of processed artists and an empty dataframe

```{r, eval=FALSE}
artists <- test_df$artist_name %>% as.character()
tracks <- data.frame()

//TODO check accuracy of the processed data

for (i in 1:length(artists)) {
  # Get the current artist
  artist <- artists[i]
  print(str_c("Processing Artist: ", artist))
  
  # Get artist's albums
  albums <- artist %>% get_artist_albums()
  print("Pulled Albums")
  
  # Compile all tracks
  if (nrow(albums) > 0) {
    tracks <- albums %>%
      get_album_tracks() %>%
      rbind(tracks,.)
    print("Pulled Tracks")
  } else {
    print(str_c(artist, " does not have an album"))
  }
}
  
# Get tracks metadata
tracks <- tracks %>%
  full_join(.,get_track_audio_features(.))

```

## Compiling 

## Scraping Data from _Billboard's Top 100_

With _Spotify_, there are only information of songs from 2017 to present day. In order extrapolate more data from more distant history, we can scrape data from _Billboard's Top 100 Songs_ which contains a top 100 list of previous years from 

# Data Tidying

# Resources

There are various resources that can be used for reference:


