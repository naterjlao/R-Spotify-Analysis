---
title: "An Analysis of Spotify's Top 200 Worldwide Daily Song Rankings in 2017"
author: "Nathaniel Lao"
date: "5/18/2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# Introduction

_Spotify_ has become one of the most popular applications that offer music streaming on popular mobile and desktop devices. Due to its popularity, the streaming trends of _Spotify_ users can provide a sample of a song's popularity across the world. As a professional musician, I am curious of the life and death of top songs in the industry and I wish to gain some insight on whether or not it is beneficial to releases songs in batches (i.e. albums) or at one of a time (i.e. singles).

In this analysis, we will explore the common <!--- BLAH BLAH --->

<!--- MORE TOPICS --->
We can extract data from _Billboard Top 100 Songs of All Time_: http://billboardtop100of.com/ for analysis.

# Setting Up RStudio

For this project, we will need to install and mount a number libraries for use in analysis.

The libraries that are needed to be installed as dependencies for the `spotifyr` class are `stringdist` and `devtools`. We can then install the _devloper_ version of `spotifyr` from _GitHub_. These installation should only be called once per system.

```{r install_pck,eval=FALSE}
# The following is needed for the spotifyr package
install.packages('stringdist')
install.packages('devtools')
devtools::install_github('charlie86/spotifyr')
```

We can now mount the needed libraries.

```{r setup_pck,message=FALSE,error=FALSE}
library(dplyr)
library(tidyr)
library(lubridate)
library(stringr) # For string manpulation
library(spotifyr) # Allows for extracting metadata for songs
library(ggplot2)
```

# Data Wrangling

## Scraping Data from Spotify's Top 200

_Spotify_ keeps records of the daily _Top 200 Charts_ for various countries in a dedicated site: https://spotifycharts.com/. We can scrape data systematically by downloading the CSV file using the url: https://spotifycharts.com/regional/global/daily/YEAR-MO-DY/download. For this analysis, we will scrape data from the 'global' dataset in daily values. The scope of this analysis will consider the entire 2017 year: January 1st, 2017 until January 1st, 2018.

In order to pull data from the url, we will define the `start_date` and `end_date` variables as well as the `url_prefix` and the `url_suffix`. These strings will be concatenated to the front and end of the start date so as to have a proper final url for scraping. We can define a function, `get_top200` that accepts a date, appends the necessary strings together to form a URL and finally pull the `data.frame` object via the `read.csv` function. In addition to pull the data, we will mutate the data frame so as to have a `Date` attribute so that it will be easy to distinguish between entities (songs) of different dates.

```{r get_top200}
# Get start and end date
start_date <- as.Date("2017/1/1")
end_date <- as.Date("2018/1/1")

# Define URL prefix and suffix
url_prefix <- 'https://spotifycharts.com/regional/global/daily/'
url_suffix <- '/download'

# List of Column Names that should exist in the dataframe
col_names = c("Position","Track.Name","Artist","Streams","URL")

# Define a function that pulls data from a certain date
get_top200 <- function(date) {
  url <- str_c(url_prefix,
               format.Date(date),
               # TODO The following is needed if the date is the current date
               #ifelse(date == Sys.Date(),'latest',format.Date(date)),
               url_suffix)
  # TODO Uncomment for debug
  # print(str_c("Pulling from ",url))
  
  # Pull data from web
  top200_df <- read.csv(url)
  
  # There are sometimes file that do not exist, this handles the exception
  ifelse(all(colnames(top200_df) %in% col_names),
         top200_df <- top200_df %>% mutate(Date = date), # Create a date attribute
         top200_df <- data.frame()) # Return an empty data frame if invalid
  
  top200_df
}
```

We can now use the code to pull all of the data frames of the `Top 200 Global Songs` and combine them via the `rbind` function. (The `rbind` function basically combines two data frames, so long as they hae the same columns. Note that this is different from `join`, as `join` serves to resolve entities between two datasets.) Since importing the data from the web takes a relatively long time, it would be prudent to save the newly created data frame into a `csv` file.

```{r import_top200_setup}
# Set a variable for the processing date
date <- start_date
# Set the empty dataframe to be added on
top200_df <- data.frame()
# Name of output file
file_output <- "data/2017top200songs.csv"
```

```{r import_top200,eval=FALSE}
# Iterate every date from start to end
while (date <= end_date) {
  top200_df <- top200_df %>%
    rbind(get_top200(date))
  date <- date + 1
}

# Save the file to csv
top200_df %>% write.csv(file_output)
```

```{r,echo=FALSE}
if (nrow(top200_df) == 0) { top200_df <- read.csv(file_output) %>% select(-X)}
```

```{r}
# Display the data
top200_df %>%
  head(10)
```

## Retrieving Song Metadata using `spotifyr`

_Spotify_ is a developer friendly platform, an API is available for use in various languages: https://developer.spotify.com/. In the _R_ development language, there exists a wrapper library for the _Spotify_ API, `spotifyr` that can be used to extract data. Special thanks to _charlie86_ for this code: https://github.com/charlie86/spotifyr.

```{r client_login,eval=TRUE,include=FALSE}
client_id = 'f6eb05cabe1b40918336d70c9b9d157e'
client_secret = '5615c7eb790a471fba93915d37e8a367'
```

In order to use `spotifyr`, it is necessary to generate a `client_id` and a `client_secret` code from the developer site. Since these codes are not meant to be public, I have previously set the codes to their respective variables. The following code will set these values to System Environment variables `SPOTIFY_CLIENT_ID` and `SPOTIFY_CLIENT_SECRET` which will be used by the `get_spotify_access_token()` method present in every `spotifyr` requests.

```{r setup_spotifyr,eval=TRUE}
Sys.setenv(SPOTIFY_CLIENT_ID = client_id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = client_secret)
```


### SAMPLE CODE FOR TESTING

```{r,eval=FALSE}
beatles_df <- get_artist_audio_features('The Beatles') 
led_zeppelin_df <- get_artist_audio_features('Led Zeppelin')
rolling_stones_df <- get_artist_audio_features('The Rolling Stones')
```

```{r,eval=FALSE}
band_df <- rolling_stones_df
```

```{r,eval=FALSE}
## GET THE ACOUSTICNESS OF SONGS
band_df %>%
  select(track_name, acousticness) %>%
  arrange(desc(acousticness)) %>%
  mutate(acousticness = round(acousticness * 100)) %>%
  unique()
```

```{r, eval=FALSE}
band_df %>%
  ggplot(mapping=aes(x=tempo)) +
  geom_density()
```

## Scraping Data from _Billboard's Top 100_

With _Spotify_, there are only information of songs from 2017 to present day. In order extrapolate more data from more distant history, we can scrape data from _Billboard's Top 100 Songs_ which contains a top 100 list of previous years from 

# Data Tidying

# Resources

There are various resources that can be used for reference:


